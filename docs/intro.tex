\section{Introduction}

% 1Click Task
Information retrieval (IR) aims to find relevant information for information needs.
Most existing IR techniques consider the relevant information at document levels and rank documents according to their relevance to users' queries.
Alternatively, 1Click search defines the information retrieval task in a finer granularity, i.e., information units (iUnits).
In particular, it requires systems to return short answering text that contains these relevant information units.

\missing{example queries, example iUnits, Figure~\ref{fig:example}}

\missing{1-Click Search Input: Query and 200 ranked Web pages}

\missing{Output: a 1,000 characters summary}

\missing{Summary should contain the information the pages relevant to the query.}

\missing{A research challenge part of NTICR Queries belong to 8 types (celebrities, how to, location, etc), but the type is not explicit}

\begin{figure}
\begin{tabular}{ll}
\textbf{Query:} & \texttt{Whitney Houston Death} \\
& \\
\textbf{Relevant information:} & 
  \begin{minipage}{10cm}\textit{On February 11, 2012, Houston was found dead 
  in suite 434 at the Beverly Hilton Hotel, submerged in the bathtub. } \end{minipage} \\
& \\
 & \begin{tabular}{ll}
V001001 &February 11, 2012\\
V001002 &Beverly Hilton Hotel\\
V001003 &suite 434 \\
V001004 &submerged in the bathtub
\end{tabular}\\
& \\
& \begin{minipage}{10cm}\textit{the cause of Houston's death was drowning and 
  the "effects of atherosclerotic heart disease and cocaine use".}  \end{minipage} \\
& \\
 & \begin{tabular}{ll}
    V002001 &drowning\\
    V002002 &atherosclerotic heart disease\\
    V002003 &cocaine
\end{tabular}\\
\end{tabular}
\caption{Query Example.}
\label{fig:example}
\end{figure}


% Motivation: DeepQA for 1Click Task
In this work, we inspire ourselves on the DeepQA framework looking to adapt it for the 1Click task.
DeepQA framework has been successfully used in IBM Watson QA system for both Jeopardy Challenge and TREC QA task \cite{ferrucci_etal_AI10}.
Generally, 1Click task is different from QA task, because it usually does not contain question word (except queries in QA category) and it is usually more general than a question.
However, they both heavily rely on the search component, and they both need to score and organize the information candidates (iUnits in 1Click task and relevant nuggets in QA literatures).
The advantage of DeepQA framework is that it can integrate a large number of knowledge learnt by diverse techniques to improve the answering performance.

\missing{Say something in the lines that we wanted to simplify DeepQA and apply the same approach without query type identification}


% Framework
The main idea of DeepQA framework is that each component is responsible for generating knowledge and corresponding confidence about the answer, and then we need to integrate these information to get the final result.
There are three main components in the framework:

\begin{itemize}
\item Candidate Generation: generate candidate iUnits for a specific query
\item Candidate Scoring: we can score candidate iUnits according to its features such as type, evidence strength, etc.
\item Candidate Organization: organize the candidate in a piece of compact text
\end{itemize}

\missing{Architecture figure}

In the following three sections, we will describe Hunter Gatherer system\footnote{Source code for Hunter-Gatherer is available at \url{https://github.com/jinghe/hunter-gatherer}} in detail.

